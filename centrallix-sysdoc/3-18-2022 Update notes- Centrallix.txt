Project: Finding Duplicate Records (LightSys)
Team:
- Luke Avent
- Nathan Moyes
- Brian Smith

Files Added/Edited:
    * Created new branch on the Centrallix GitHub Repository: “utf-8-duplicate-checking”
        o The original “duplicate-checking” and “utf-8” branches were merged into this new branch for development.

Implementing UTF-8 Compatibility <DONE>:

Creation and merging of new branch in Centrallix Repository 
    * Began by creating a new branch under utf-8 (utf-8-duplicate-checking) for prototyping
    * Merged the duplicate-checking branch of Centrallix (duplicate-checking)
        o Merge conflicts were resolved: Most content from both branches kept

Updating Levenshtein for UTF-8
    * Levenshtein analysis was reevaluated updated along with the method for similarity analysis and the fuzzy-compare query
        o Levenshtein method revised by converting input string into a wide char string using the mbstowcs()  or multi-byte-string to wide character string function before feeding into standard Levenshtein algorithm.
        o Similarity function1 tweaked by using a 256-size character frequency table rather than in a 36-size table (previous version, only letters and numbers).
    * Larger table size allowed mapping of UTF-8 characters to a new index in the 256-size character frequency table
    * Multi-byte characters were converted to single-byte characters via this process
        o Last byte in each character was bit-reversed, then all bytes within that character were put together bitwise by an exclusive or.
        o Tested Latin and Greek character sets for functionality.
        o Mild modification to fuzzy_compare to compensate for new charset length.
    * levenshtein() added to SQL as a query-callable function
    * Works by counting and comparing frequency occurrences of each letter

3/14/2022 - 3/18/2022	Finding Duplicate Records


